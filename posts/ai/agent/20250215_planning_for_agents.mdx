---
title: 智能体的规划能力[译]
date: 2025-02-15
description: 本文深入探讨了 AI Agent 的规划能力这一关键挑战，分析了当前 LLM 在规划和推理方面的局限性，并介绍了通用认知架构与特定领域认知架构两种改进方案。通过实际案例展示了如何构建更可靠的 Agent 系统，以及未来发展趋势。
category: ai
tags: AI Agent, Planning, Cognitive Architecture, LangChain, LangGraph, Function Calling, Flow Engineering, LLM Reasoning
cover: https://media.ginonotes.com/covers/cover_agent_planing.jpeg
slug: planning-for-agents
---

<div className="mx-auto max-w-prose rounded-lg border bg-gradient-to-br px-4 shadow-md text-lg leading-relaxed">
  本文是 LangChain 博客上关于智能体 (AI Agent) 的系列文章的第四篇，深入探讨了 AI Agent 的规划能力这一关键挑战，分析了当前 LLM 在规划和推理方面的局限性，并介绍了通用认知架构与特定领域认知架构两种改进方案。
</div>

在今年三月的红杉资本 AI Ascent 大会上，我谈到了 Agent 的三个局限性：规划、用户体验和记忆。您可以在[这里](https://www.youtube.com/watch?v=pBBe1pk8hf4)观看当时的演讲。本文将更深入地探讨 Agent 的规划能力。

如果您询问任何使用 LLM 构建 Agent 的开发者，他们很可能会指出 Agent 规划和推理能力不足是影响其可靠性的一个主要痛点。那么，Agent 的规划到底意味着什么？目前我们看到人们是如何克服这个缺点的？Agent 规划和推理的未来又会是什么样子的？我们将在下文逐一展开分析。

### 规划 (Planning) 和推理 (Reasoning) 究竟指什么？

Agent 的规划和推理能力指的是 LLM 对行动方案的思考，既涵盖短期步骤，也涉及长期计划。LLM 会评估所有可用的信息，并确定一系列需要执行的步骤，同时确定首先应执行哪一步。例如，在预订机票时，Agent 需要考虑航班时间、价格、中转等多个因素，并制定相应的行动计划。

大多数时候，开发者使用[函数调用](https://platform.openai.com/docs/guides/function-calling)（也称为工具调用）来让 LLM 选择要采取的行动。函数调用是 OpenAI 于 2023 年 6 月首次添加到 LLM API 的功能，并在同年末至次年初被其他平台相继采用。通过函数调用，您可以为不同的函数提供 JSON 模式，并让 LLM 输出与其中一个（或多个）模式匹配的对象。有关如何操作的更多信息，请参阅我们的[指南](https://python.langchain.com/v0.2/docs/how_to/tool_calling/)。

函数调用用于让 Agent 选择立即执行的行动。但对于复杂任务，通常需要按顺序采取多个行动，以实现长期目标。这种长期规划和推理对 LLM 来说是一项更艰巨的任务，原因有以下几点：首先，LLM 必须考虑一个更长时间范围的目标，然后回溯到一个短期行动中。其次，随着 Agent 不断采取行动，其结果反馈给 LLM 后，上下文窗口逐渐增大，进而使 LLM 更容易受到干扰并表现欠佳。

与 LLM 世界中的大多数事物一样，很难准确衡量当前模型在规划和推理方面的表现。有一些合理的基准，例如 [Berkeley 函数调用排行榜](https://gorilla.cs.berkeley.edu/leaderboard.html)，用于评估函数调用。我们还对评估多步骤应用程序做了一些[研究](https://blog.langchain.dev/benchmarking-agent-tool-use/)。但了解这种情况的最佳方法是为您的 **特定问题** 构建一个评估集，并尝试[自己进行评估](https://docs.smith.langchain.com/tutorials/Developers/agents)。

<div className="my-4 rounded-lg bg-blue-50 p-4">
  💡 从经验来看，人们普遍认为规划和推理仍然没有达到现实世界任务所需的水平。
</div>

### 目前有哪些改进 Agent 规划能力的方法？

改进规划的一个关键方法是确保 LLM 拥有适当推理和规划所需的所有信息，这包括提供清晰的任务目标、相关的背景知识以及可用的工具和资源。尽管听起来很简单，但传递给 LLM 的提示往往信息不足，使得 LLM 无法做出合理的决策。添加检索步骤或澄清提示说明是一个简单的改进，这就是为什么实际查看数据并了解 LLM 实际看到的内容至关重要。

之后，我建议您尝试更改应用程序的[认知架构](https://blog.langchain.dev/what-is-a-cognitive-architecture/)。我所说的 "认知架构" 是指您的应用程序用于推理的数据工程逻辑。您可以考虑使用两种认知架构来改进推理：通用认知架构和特定领域认知架构。

### 通用认知架构 vs 特定领域认知架构

通用认知架构旨在通过通用方法提升推理能力，适用于各类任务。一个很好的例子是 "计划和解决" 架构。[这篇论文](https://arxiv.org/abs/2305.04091) 探讨了一种架构，首先提出一个计划，然后执行该计划中的每个步骤。另一种通用架构是 Reflexion 架构。[这篇论文](https://arxiv.org/abs/2303.11366) 探讨在 Agent 完成一项任务后，添加一个明确的 "反思" 步骤，以反思它是否正确地完成了任务。

虽然这些想法显示出改进，但它们通常过于通用，无法供生产中的 Agent 实际使用。相反，我们看到 Agent 是使用特定领域的认知架构构建的。这通常体现在特定领域的分类/路由步骤、特定领域的验证步骤中。规划和反思的一些通用思想可以应用于此，但它们通常以特定领域的方式应用。

作为一个具体的例子，让我们看看 [AlphaCodium 论文](https://www.codium.ai/products/alpha-codium/)。它通过使用他们所谓的 "流程工程"（Flow Engineering，一种认知架构的实现方式）实现了最先进的效果。请参见下图，了解他们使用的流程。

![Flow Engineering](https://media.ginonotes.com/images/20250215_planning_for_agents/flow_engineering.png)

该流程非常特定于他们试图解决的问题。他们逐步告诉 Agent 该做什么 —— 提出测试，然后提出解决方案，然后迭代更多的测试，等等。这种认知架构是高度特定于领域的 —— 例如，它不会帮助您写文章。

### 为什么特定领域的认知架构如此有帮助？

我喜欢用两种方式来思考这个问题。

首先：您可以将其视为仅仅是另一种向 Agent 传达它应该做什么的方法。您可以通过提示说明传递指令，或在代码中直接定义特定规则。无论是通过提示说明还是代码定义规则，两种方法均具有可行性！代码是传达您想要发生的事情的 **绝佳** 方式。

其次，这种方法实际上是将部分规划责任从 LLM 转移到工程师身上，相当于我们预先定义了 LLM 执行任务的流程框架。当然，我们并没有从 LLM 中删除所有规划，因为我们仍然要求它在某些情况下进行一些规划。

例如，让我们回顾一下上面的 AlphaCodium 示例。流程中的步骤基本上是我们为 LLM 做规划！我们告诉它首先编写测试，然后编写代码，然后运行测试，等等。这大概是作者认为编写软件的好计划。如果他们正在计划如何解决问题，他们会这样做。他们没有在提示中告诉 LLM 这样做 —— 在提示中，它可能会忽略它，不理解它，没有所有的细节 —— 而是通过构建特定领域的认知架构来告诉系统这样做。

<div className="my-4 rounded-lg bg-blue-50 p-4">
  💡 我们看到在生产中几乎所有先进的智能体实际上都有一个非常特定的领域和定制的认知架构。
</div>

我们正在使用 [LangGraph](https://github.com/langchain-ai/langgraph) 使构建这些定制认知架构变得更容易。LangGraph 的一个重要关注点是可控性。我们将 LangGraph 设计得非常底层和高度可控 —— 这是因为我们已经看到，要创建一个可靠的定制认知架构，100% 需要这种级别的可控性。

### 规划和推理的未来会是什么样子？

LLM 领域一直在快速变化和发展，我们在构建应用程序时，尤其是在构建工具时，应该牢记这一点。

我目前的看法是，通用推理将越来越多地被模型层吸收。模型将变得越来越智能，无论是通过规模还是研究突破 —— 我们有理由相信这种情况将会发生。模型也将变得更快、更便宜，因此将大量上下文传递给它们将变得越来越可行。

但是，我相信无论模型变得多么强大，您始终需要以某种形式向 Agent 传达它应该做什么。因此，我相信提示和定制架构将继续存在。对于简单的任务，提示可能就足够了。对于更复杂的任务，您可能希望将它应该如何表现的逻辑放在代码中。代码优先的方法不仅更快、更可靠、更易调试，还能以更加直观和符合逻辑的方式表达需求。

我最近与红杉资本的 Sonya 和 Pat 一起参加了一个 [播客](https://podcasts.apple.com/us/podcast/langchains-harrison-chase-on-building-the/id1750736528?i=1000659385691)，讨论了这个话题。他们绘制了一个很棒的图表，显示了提示、认知架构和模型的作用/重要性如何随着时间的推移而演变。

![Prompt, Cognitive Architecture, and LLM](https://media.ginonotes.com/images/20250215_planning_for_agents/prompt_cognitive_arch_and_llm.png)

因此，尽管 LLM 的规划和推理能力必将持续进步，但我们深信，若要打造一个面向特定任务的 Agent，构建定制化的认知架构仍然是不可或缺的关键所在。这就是为什么我们对 LangGraph 的未来如此看好。

原文地址：[Planning for Agents](https://blog.langchain.dev/planning-for-agents/)

---

LangChain 智能体系列文章：

- [1. 什么是智能体？](https://www.ginonotes.com/posts/what-is-ai-agents)
- [2. 什么是认知架构？](https://www.ginonotes.com/posts/what-is-a-cognitive-architecture)
- [3. 为什么你应该外包智能体基础设施，但保留自己的认知架构](https://www.ginonotes.com/posts/outsource-agentic-infrastructure-own-cognitive-architecture)
- [4. 智能体的规划能力](https://www.ginonotes.com/posts/planning-for-agents)
- [5. 智能体的交互模式](https://www.ginonotes.com/posts/ux-for-agents)