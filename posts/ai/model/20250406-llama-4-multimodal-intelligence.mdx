---
title: Llama 4 系列：开启原生多模态 AI 创新新纪元 [译]
date: 2025-04-06
description: Meta 正式发布 Llama 4 系列大型语言模型，推出两款开源的原生多模态模型 Llama 4 Scout 和 Llama 4 Maverick，并预告了更强大的教师模型 Llama 4 Behemoth。这些模型首次采用混合专家（MoE）架构，在性能、效率和上下文长度（Scout 高达 1000 万 token）方面取得显著突破。
category: ai
tags: Llama 4, Multimodal AI, MOE, Meta, LLM, Open Source
cover: https://media.ginonotes.com/images/llama-4-multimodal-intelligence/cover.png
slug: llama-4-multimodal-intelligence
---

> 随着人工智能日益融入我们的工作与生活，对更强大、更通用、更易于访问的 AI 模型的需求也与日俱增。为此，Meta 正式推出其迄今最先进的大型语言模型系列 Llama 4，旨在开启原生多模态 AI 创新的新篇章。本次发布的核心是两款高效且强大的开源权重模型——Llama 4 Scout 和 Llama 4 Maverick。它们不仅首次将原生多模态能力（结合文本、图像等）与高效的混合专家（MoE）架构相融合，更在上下文处理长度、性能基准以及成本效益上设立了新的行业标杆。Meta 致力于通过开放这些尖端技术，赋能全球开发者和研究者，共同探索和构建下一代个性化、安全、可靠的 AI 应用未来。

![Llama 4 系列](https://media.ginonotes.com/images/llama-4-multimodal-intelligence/cover.png)

**核心看点**

*   我们发布 **Llama 4 系列的首批模型**，旨在帮助开发者和用户打造更个性化的多模态 AI 体验。
*   **Llama 4 Scout**：具备 170 亿活跃参数和 16 个专家模型，是同级别中全球性能领先的多模态模型，其性能超越所有前代 Llama 模型，且可部署于**单块 NVIDIA H100 GPU（需 Int4 量化）**。此外，Llama 4 Scout 提供业界领先的 **1000 万 token 上下文窗口**，在多项广泛应用的基准测试中表现优于 Gemma 3、Gemini 2.0 Flash-Lite 和 Mistral 3.1。
*   **Llama 4 Maverick**：具备 170 亿活跃参数和 128 个专家模型，是同级别中的顶尖多模态模型。在多项广泛应用的基准测试中，它超越了 GPT-4o 和 Gemini 2.0 Flash，同时在推理和编码方面取得了与新版 DeepSeek v3 相当的成绩，而其**活跃参数量不到后者的一半**。Llama 4 Maverick 提供了同类领先的性价比，其试验性聊天版本在 [LMArena](https://lmarena.ai/?leaderboard) 上的 **ELO 评分达到 1417**。
*   这些模型的卓越性能，得益于从 **Llama 4 Behemoth** 进行的**知识蒸馏**。Behemoth 模型拥有 2880 亿活跃参数和 16 个专家模型，不仅是我们迄今最强大的模型，也是全球顶尖的智能大语言模型之一。在多项 STEM（科学、技术、工程、数学）基准测试中，Llama 4 Behemoth 的表现优于 GPT-4.5、Claude Sonnet 3.7 和 Gemini 2.0 Pro。该模型目前仍在训练中，我们很期待在训练的同时，与大家分享更多相关细节。
*   即刻访问 [llama.com](https://www.llama.com/llama-downloads/) 和 [Hugging Face](https://huggingface.co/meta-llama) 下载 Llama 4 Scout 与 Llama 4 Maverick 模型。同时，您也可以在 WhatsApp、Messenger、Instagram Direct 以及 [Meta.AI](https://www.meta.ai/) 网站上，体验集成 Llama 4 的 Meta AI。

随着人工智能日益融入人们的日常生活，确保领先的模型与系统能够开放获取变得至关重要，这样每个人都能参与到构建个性化体验的未来之中。今天，我们激动地宣布推出迄今最先进的模型套件，为整个 Llama 生态系统提供强大支持。我们正式介绍 **Llama 4 Scout** 和 **Llama 4 Maverick**——这是首批原生多模态、具备前所未有的上下文长度、并首次采用**混合专家（MoE）架构**构建的开源权重模型。同时，我们还预告了 **Llama 4 Behemoth**，这是全球顶尖的智能大语言模型之一，也是我们迄今最强大的模型，它将作为我们新模型的“教师”。

这些 Llama 4 模型标志着 Llama 生态系统新纪元的开端。我们在 Llama 4 系列中设计了两款高效模型：**Llama 4 Scout**，拥有 170 亿活跃参数和 16 个专家模型；以及 **Llama 4 Maverick**，拥有 170 亿活跃参数和 128 个专家模型。前者可在单块 H100 GPU 上运行（采用 Int4 量化），后者则可部署在单个 H100 主机上。我们还训练了一个教师模型 **Llama 4 Behemoth**，在以 STEM 为重点的基准测试（如 MATH-500 和 GPQA Diamond）中，其表现优于 GPT-4.5、Claude Sonnet 3.7 和 Gemini 2.0 Pro。虽然 Llama 4 Behemoth 仍在训练中，我们暂不发布该模型，但我们很乐意分享更多关于我们方法的技术细节。

我们始终坚信，开放能够驱动创新，这对开发者有利，对 Meta 有利，对整个世界也有利。即日起，我们开放 Llama 4 Scout 和 Llama 4 Maverick 在 **llama.com** 和 **Hugging Face** 上的下载，让每个人都能继续使用我们的最新技术构建全新的体验。未来几天，这些模型也将通过我们的合作伙伴提供。您也可以从今天开始，在 WhatsApp、Messenger、Instagram Direct 以及 Meta.AI 网站上体验由 Llama 4 驱动的 Meta AI。

这仅仅是 Llama 4 系列的开端。我们相信，最智能的系统需要具备执行通用任务、与人类自然对话以及解决未曾见过难题的能力。赋予 Llama 在这些领域的超强能力，将为我们平台上的用户带来更好的产品，也为开发者在下一个重要的消费者和商业应用场景中创新提供更多机遇。我们将持续进行模型和产品的研究与原型设计，并将在 4 月 29 日的 LlamaCon 上分享更多关于我们的愿景 —— [欢迎注册以获取更多信息](https://www.llama.com/events/llamacon/signup/)。

无论您是基于我们模型进行开发的开发者、将模型集成到工作流的企业用户，还是仅仅对 AI 的潜力和益处感到好奇的普通用户，Llama 4 Scout 和 Llama 4 Maverick 都是为您的产品增添下一代智能的最佳选择。今天，我们很高兴能分享更多关于模型开发四个主要方面的内容，以及我们研究和设计过程中的见解。我们也迫不及待地想看到社区利用我们全新的 Llama 4 模型构建出哪些令人惊叹的新体验。

**预训练**

这些模型代表了 Llama 的最高水准，以极具吸引力的成本提供了多模态智能，并且性能超越了规模远大于自身的模型。构建下一代 Llama 模型要求我们在预训练期间采取了几种新方法。

我们全新的 Llama 4 模型是首批使用**混合专家（MoE）架构**的模型。在 MoE 模型中，处理单个 token（词元）时仅激活总参数的一小部分。MoE 架构在训练和推理方面具有更高的计算效率，并且在固定的训练 FLOPs（每秒浮点运算次数）预算下，相比传统的密集模型能提供更高的质量。

![MOE 架构](https://media.ginonotes.com/images/llama-4-multimodal-intelligence/moe.png)

以 Llama 4 Maverick 为例，该模型拥有 170 亿活跃参数和 4000 亿总参数。为了提高推理效率，我们**交替使用了密集层和混合专家（MoE）层**。MoE 层包含 128 个路由专家模型和一个共享专家模型。每个 token 都会被发送到共享专家模型，并同时路由到 128 个路由专家模型中的一个。因此，虽然所有参数都存储在内存中，但在服务这些模型时只有总参数的一个子集被激活。这通过降低模型服务成本和延迟来提高推理效率——Llama 4 Maverick 可在单个 NVIDIA H100 DGX 主机上运行以便于部署，或通过分布式推理实现最高效率。

Llama 4 模型采用**原生多模态设计**，通过**早期融合**（early fusion）技术，将文本和视觉 token 无缝集成到统一的模型主干中。早期融合是一个重大进步，因为它使我们能够使用大量未标记的文本、图像和视频数据联合预训练模型。我们还改进了 Llama 4 中的**视觉编码器**。该编码器基于 MetaCLIP，但与一个冻结的 Llama 模型联合进行了单独训练，以更好地使编码器适应大语言模型（LLM）。

我们开发了一种新的训练技术，称之为 **MetaP**，使我们能够可靠地设置关键的模型超参数，例如每层学习率（learning rate）和初始化尺度（initialization scales）。我们发现选定的超参数在不同的批次大小、模型宽度、深度和训练 token 数量下具有良好的迁移性。Llama 4 通过在 **200 种语言**上进行预训练，支持了开源微调工作，其中超过 100 种语言的 token 量超过 10 亿，多语言 token 总量比 Llama 3 多 10 倍。

此外，我们专注于高效的模型训练，采用了 **FP8 精度**，在不牺牲质量的前提下，确保了高模型 FLOPs 利用率——在使用 FP8 精度和 3.2 万块 GPU 预训练我们的 Llama 4 Behemoth 模型时，我们实现了高达 **390 TFLOPs/GPU** 的计算效率。用于训练的数据混合总量超过 **30 万亿 token**，是 Llama 3 预训练数据量的两倍多，包含了多样化的文本、图像和视频数据集。

我们继续进行我们称之为“**中期训练**”（mid-training）的阶段，通过新的训练方案来提升核心能力，包括使用专门的数据集进行**长上下文扩展**。这使我们能够提高模型质量，同时为 Llama 4 Scout 解锁了业界领先的 **1000 万 token 输入上下文长度**。

**新模型的后训练**

我们最新的模型提供了不同规模的选项，以适应各种用例和开发者需求。**Llama 4 Maverick** 在图像和文本理解方面具有无与伦比、行业领先的性能，能够创建跨越语言障碍的复杂 AI 应用。作为我们通用助手和聊天场景的**主力模型**，Llama 4 Maverick 非常适合精确的图像理解和创造性写作。

在后训练 Llama 4 Maverick 模型时，最大的挑战是在多种输入模态、推理能力和对话能力之间保持平衡。对于混合模态，我们提出了一种精心设计的**课程策略**（curriculum strategy），与单一模态专家模型相比，这种策略不会牺牲性能。在 Llama 4 中，我们改进了后训练流程，采用了不同的方法：**轻量级监督微调（SFT）-> 在线强化学习（RL）-> 轻量级直接偏好优化（DPO）**。一个关键的经验是，SFT 和 DPO 可能会过度约束模型，限制其在在线 RL 阶段的探索，从而导致在推理、编码和数学等领域表现欠佳。为了解决这个问题，我们使用 Llama 模型作为评判器，移除了超过 50% 被标记为“简单”的数据，并在剩余的较难数据集上进行了轻量级 SFT。在随后的多模态在线 RL 阶段，通过仔细选择更难的提示，我们在性能上实现了阶段性提升。此外，我们实施了一种**持续在线 RL 策略**，即交替进行模型训练和使用模型持续过滤并保留中等到困难难度的提示。这种策略在计算与准确性的权衡方面被证明是非常有益的。然后，我们进行了轻量级 DPO 来处理与模型响应质量相关的边界情况（corner cases），有效地在模型的智能和对话能力之间取得了良好平衡。整个流程架构以及带有自适应数据过滤的持续在线 RL 策略，最终造就了一款行业领先、具有顶尖智能和图像理解能力的通用聊天模型。

作为一款通用大语言模型，Llama 4 Maverick 拥有 170 亿活跃参数、128 个专家模型和 4000 亿总参数，与 Llama 3.3 70B 相比，以更低的成本提供了高质量。Llama 4 Maverick 是同类最佳的多模态模型，在编码、推理、多语言、长上下文和图像基准测试中超越了 GPT-4o 和 Gemini 2.0 等同类模型，并且在编码和推理方面与规模大得多的 DeepSeek v3.1 具有竞争力。

![Benchmark](https://media.ginonotes.com/images/llama-4-multimodal-intelligence/benchmarks.png)

我们规模较小的模型 **Llama 4 Scout** 是一款通用模型，拥有 170 亿活跃参数、16 个专家模型和 1090 亿总参数，为其同类产品提供了顶尖性能。Llama 4 Scout 将支持的上下文长度从 Llama 3 的 12.8 万 token **大幅增加到行业领先的 1000 万 token**。这开启了一个充满可能性的世界，包括多文档摘要、解析大量用户活动以实现个性化任务，以及对庞大代码库进行推理。

Llama 4 Scout 在预训练和后训练阶段都使用了 25.6 万 token 的上下文长度，这赋予了基础模型先进的**长度泛化能力**。我们在诸如“大海捞针”检索（文本）以及处理超过 1000 万 token 代码的累积负对数似然（NLLs）等任务中展示了令人信服的结果。Llama 4 架构的一个关键创新是使用了**不带位置嵌入的交错注意力层**。此外，我们采用**推理时注意力温度缩放**来增强长度泛化能力。我们称之为 **iRoPE 架构**，其中“i”代表“交错”（interleaved）注意力层，强调支持“无限”（infinite）上下文长度的长期目标，“RoPE”指大多数层中使用的旋转位置嵌入（Rotary Position Embeddings）。

![need-for-large-context-window](https://media.ginonotes.com/images/llama-4-multimodal-intelligence/needle.png)

![Sequence Position](https://media.ginonotes.com/images/llama-4-multimodal-intelligence/sequence_position.png)

我们用各种各样的图像和视频帧静态图训练了这两个模型，使其具备广泛的视觉理解能力，包括对时间性活动和相关图像的理解。这使得模型能够轻松处理带有文本提示的多图像输入，以完成视觉推理和理解任务。模型在预训练中最多处理 48 张图像，我们在后训练中测试了最多 8 张图像，效果良好。

**Llama 4 Scout** 在**图像定位**（image grounding）方面也是同类最佳，能够将用户提示与相关的视觉概念对齐，并将模型响应锚定到图像中的特定区域。这使得大语言模型能够进行更精确的视觉问答，更好地理解用户意图并定位感兴趣的对象。Llama 4 Scout 在编码、推理、长上下文和图像基准测试中同样超越了同类模型，并且性能优于所有先前的 Llama 模型。

![Instruction Tuned](https://media.ginonotes.com/images/llama-4-multimodal-intelligence/instruction-tuned.png)

这些新模型是重要的基石，将有助于实现人与人之间连接的未来。秉承我们对开源的承诺，我们即将在 **llama.com** 和 **Hugging Face** 上提供 Llama 4 Maverick 和 Llama 4 Scout 的下载，并很快会通过最广泛使用的云和数据平台、边缘计算芯片以及全球服务集成商提供。

**挑战 Llama 新极限：2 万亿参数的 Behemoth**

我们激动地预告 **Llama 4 Behemoth**，这是一个教师模型，在其同类模型中展现了先进的智能水平。Llama 4 Behemoth 同样是一个多模态混合专家模型，拥有 **2880 亿活跃参数**、16 个专家模型，以及**接近 2 万亿的总参数**。它在数学、多语言和图像基准测试方面，为非推理模型提供了顶尖性能，是教授较小 Llama 4 模型的理想选择。我们以 Llama 4 Behemoth 作为教师模型，对 Llama 4 Maverick 模型进行了**协同蒸馏**（codistillation），这在最终任务评估指标上带来了显著的质量提升。我们开发了一种新颖的蒸馏损失函数，该函数在训练过程中动态地权衡软目标（soft targets）和硬目标（hard targets）。在预训练期间进行协同蒸馏，分摊了为学生模型训练所用的大部分数据计算蒸馏目标所需的、资源密集型前向传播（forward passes）的计算成本。对于学生模型训练中引入的额外新数据，我们在 Behemoth 模型上运行前向传播来创建蒸馏目标。

![Behemoth](https://media.ginonotes.com/images/llama-4-multimodal-intelligence/behemoth.png)

对一个拥有 2 万亿参数的模型进行后训练也是一项重大挑战，要求我们彻底改革和调整方案，首先从数据规模入手。为了最大化性能，我们不得不裁剪掉 **95%** 的 SFT 数据（相比之下，较小模型为 50%），以达到对质量和效率的必要关注。我们还发现，进行轻量级 SFT 之后再进行大规模强化学习（RL），在模型的推理和编码能力方面带来了更显著的提升。我们的 RL 方案专注于通过使用策略模型进行 **pass@k 分析**来采样困难提示，并设计了一个提示难度递增的训练课程。我们还发现，在训练过程中动态过滤掉优势（advantage）为零的提示，以及构建包含来自多种能力的混合提示的训练批次，对于提升模型在数学、推理和编码方面的性能至关重要。最后，从各种系统指令中进行采样，对于确保模型保持其在推理和编码方面的指令遵循能力（instruction following ability），并且能够在各种任务中表现良好至关重要。

为 2 万亿参数模型扩展 RL 规模也需要改进我们底层的 RL 基础设施，因为其规模前所未有。我们优化了 MoE 并行化设计以提高速度，从而实现了更快的迭代。我们开发了一个**完全异步的在线 RL 训练框架**，增强了灵活性。与现有的分布式训练框架（后者为了将所有模型堆叠在内存中而牺牲了计算内存）相比，我们的新基础设施能够将不同模型灵活地分配到独立的 GPU 上，根据计算速度平衡多个模型之间的资源。这项创新使得训练效率相比前几代**提高了约 10 倍**。

**安全保障与防护措施**

我们的目标是开发最有帮助、最有用的模型，同时防范和减轻最严重的风险。我们遵循了《**开发者使用指南：AI 保护措施**》中概述的最佳实践来构建 Llama 4。这包括在模型开发的每个层面集成缓解措施（mitigations），从预训练、后训练到可调整的系统级缓解措施，以保护开发者免受恶意用户的攻击。通过这样做，我们赋能开发者为其基于 Llama 的应用创建有益、安全且适应性强的体验。

**预训练和后训练缓解措施**

*   在预训练阶段，我们使用数据过滤结合其他数据缓解措施来保护模型。
*   在后训练阶段，我们应用一系列技术来确保我们的模型符合对用户和开发者有益的策略，包括在每个阶段使用适当级别的安全数据。

**系统级方法**

在系统层面，我们开源了几种安全防护措施，有助于识别和防范潜在有害的输入和输出。这些工具可以集成到我们的 Llama 模型以及其他第三方工具中：

*   **Llama Guard**：基于我们与 MLCommons 共同开发的风险分类法（[hazards taxonomy](https://arxiv.org/abs/2404.12241)）构建的输入/输出安全大语言模型。开发者可以用它来检测输入或输出是否违反了他们为特定应用创建的策略。
*   **Prompt Guard**：一个基于大量攻击语料库训练的分类器模型，能够检测明确的恶意提示（**越狱，Jailbreaks**）以及包含注入输入的提示（**提示注入，Prompt Injections**）。
*   **CyberSecEval**：一系列评估方法，帮助 AI 模型和产品开发者理解并降低生成式 AI 的网络安全风险。

开发者反馈，这些工具在能够根据其应用进行定制时最为有效和有帮助。我们为开发者提供了一个开放的解决方案，以便他们能够根据自身需求创建最安全、最有效的体验。我们也将继续与全球合作伙伴合作，创建有利于开源社区的行业系统标准。

**评估与红队测试**

我们以受控且可重复的方式，对模型在各种场景和用例中进行系统性测试。测试产生的数据将被反馈到后训练过程中。

我们使用**对抗性动态探测**（adversarial dynamic probing），结合自动化和人工测试，在广泛的主题上对模型进行压力测试。我们在理解和评估潜在模型风险方面取得了进展。一个例子是我们新开发的**生成式攻击智能体测试（GOAT）**。GOAT 通过模拟中等技能水平的对抗性行为者的多轮交互，解决了传统**红队测试**（red-teaming）的局限性，帮助我们扩大测试覆盖范围并更快地发现漏洞。通过将自动化加入我们的测试工具包，GOAT 使我们的人类专家红队能够专注于更新颖的对抗领域，而自动化则专注于已知的风险领域。这使得流程更加高效和有效，并使我们能够构建更全面的风险定量和定性图景。

**解决大语言模型中的偏见问题**

众所周知，所有领先的大语言模型都存在偏见问题——特别是在处理具争议性的政治和社会议题时，它们历史上存在偏左的倾向。这归因于互联网上可用的训练数据类型。

我们的目标是消除我们 AI 模型中的偏见，并确保 Llama 能够理解和阐述争议性议题的各方观点。作为这项工作的一部分，我们正持续提高 Llama 的响应能力，使其能够回答问题，能够回应各种不同观点而不做评判，并且不偏袒某些观点。

我们在本次发布中就这些努力取得了进展——Llama 4 的表现显著优于 Llama 3，并且与 Grok 相当：

*   Llama 4 在具争议性的政治和社会议题上整体**拒答率更低**（从 Llama 3.3 的 7% 降至 2% 以下）。
*   Llama 4 在拒答哪些提示方面**显著更加平衡**（在一组具争议性的议题问题上，不平等响应拒答的比例现在低于 1%）。
*   我们的测试表明，在一组涉及争议性政治或社会议题的提示上，Llama 4 表现出**强烈政治倾向的回应率与 Grok 相当**（且约为 Llama 3.3 的一半）。

虽然我们正在取得进展，但我们深知还有更多工作要做，并将继续努力进一步降低这一比率。我们为迄今取得的进展感到自豪，并继续致力于实现消除模型整体偏见的目标。

**探索 Llama 生态系统**

模型智能固然重要，但人们也希望模型能够以接近人类的速度进行个性化回应。作为我们迄今最先进的模型，Llama 4 经过优化以满足这些需求。

当然，模型只是将这些体验带入现实的更大生态系统的一部分。我们关注的是整个技术栈（full stack），包括新的产品集成。我们期待继续与我们的合作伙伴和开源社区进行对话，一如既往，我们迫不及待地想看到人们在新的 Llama 生态系统中构建出丰富多彩的体验。

即刻访问 **llama.com** 和 **Hugging Face** 下载 Llama 4 Scout 与 Llama 4 Maverick 模型。同时，您也可以在 WhatsApp、Messenger、Instagram Direct 以及 Meta.AI 网站上，体验集成 Llama 4 的 Meta AI。

原文链接：[The Llama 4 herd: The beginning of a new era of natively multimodal AI innovation](https://ai.meta.com/blog/llama-4-multimodal-intelligence/)