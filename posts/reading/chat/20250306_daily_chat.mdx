---
title: 【每日一问】MCP 是什么？有什么用？
date: 2025-03-06
description: 大型语言模型 (LLM) 能力虽强，但缺乏与外部世界有效连接的标准化方式。模型上下文协议 (MCP) 正是为了解决这一问题而生，它定义了一套开放协议，让 AI 模型能够以统一的方式扩展上下文信息、调用外部工具，从而突破自身局限，更好地服务于各种应用场景。
category: reading
tags: Daily Chat, MCP, LLM, Tool, Agent, Integration
cover: https://media.ginonotes.com/covers/cover_daily_chat_20250306.jpeg
slug: daily-chat-20250306
---

## 引言

在人工智能浪潮汹涌澎湃的当下，大型语言模型（LLM）正以前所未有的速度重塑人机交互的未来。它们在自然语言理解和生成方面展现出惊人的能力，然而，LLM 潜力的充分发挥，很大程度上受限于其与外部世界的连接能力 -- 如何有效获取必要的上下文信息，以及如何灵活调用各种工具和服务，已成为制约 LLM 应用发展的关键瓶颈。

长期以来，不同的 AI 厂商和应用开发者各自为政，针对特定模型或平台构建定制化的工具集成方案，导致生态碎片化严重，资源难以复用，开发成本居高不下。正是在这样的背景下，模型上下文协议（Model Context Protocol, MCP）应运而生。它犹如 AI 应用领域的 "USB-C 接口"，旨在建立一套开放、标准化的协议，规范应用程序如何向 LLM 提供上下文数据和调用外部工具，从而从根本上变革 LLM 与外部世界交互的方式。

MCP 的出现意味着什么？它能否真正打破 AI 工具集成的壁垒，构建一个互联互通、繁荣发展的 AI 应用生态？它又将如何赋能开发者，加速各种创新型 AI 应用的落地？为了深入剖析 MCP 的技术架构、核心优势、应用场景，以及它在 AI 生态系统中所扮演的角色，我让 ChatGPT 进行了一次深入研究，并形成了这份详尽的报告，欢迎阅读。

## 对话内容

![对话内容1](https://media.ginonotes.com/images/20250306_daily_chat/chatsession1.png)
![对话内容2](https://media.ginonotes.com/images/20250306_daily_chat/chatsession2.png)
![对话内容3](https://media.ginonotes.com/images/20250306_daily_chat/chatsession3.png)

## 小记

- **开放标准协议，促进行业互联互通**: 模型上下文协议 (MCP) 是一套公开的技术规范，任何 AI 模型和应用都可以遵循，旨在打破当前 AI 工具集成各自为政的局面，构建一个更加开放和互通的 AI 生态系统。

- **标准化 LLM 上下文扩展和工具调用**: MCP 的核心在于定义了 "资源" 和 "工具" 这两个关键组件，为大型语言模型 (LLM) 提供了标准化的方式来获取外部数据作为上下文，并调用外部功能来扩展自身能力，从而解决 LLM 能力局限性问题。

- **客户端-服务器架构，保障数据安全**: MCP 采用客户端 (LLM 应用) 和服务器 (数据/工具提供方) 分离的架构，通过标准协议进行通信。这种架构允许用户在本地或企业内部署 MCP 服务器，安全地将私有数据提供给 LLM 使用，无需将敏感数据直接暴露给模型提供商。

- **解决核心痛点，应用场景广泛**: MCP 主要解决 LLM 应用开发中普遍存在的上下文不足、数据访问安全、工具集成复杂等痛点。因此，MCP 在代码助手、知识库问答、自然语言数据库查询、智能助手等众多场景中都展现出巨大的应用潜力，能够显著提升 LLM 的实用性。

- **生态系统正在兴起，未来值得期待**: 目前包括 Claude、Cursor、Windsurf 等在内的多款主流 AI 工具和平台已经开始支持 MCP，并且有越来越多的开发者和社区加入到 MCP 生态建设中。随着 MCP 标准的不断完善和生态的日益壮大，它有望成为未来 AI 应用开发的基础设施，推动 AI 技术更深入地融入各行各业。